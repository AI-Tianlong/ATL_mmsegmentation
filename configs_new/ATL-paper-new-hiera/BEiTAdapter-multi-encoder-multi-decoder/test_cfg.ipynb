{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-09-02 测试, 可以跑通,loss-从5开始降低。\n",
    "\n",
    "from mmcv.transforms import (LoadImageFromFile, RandomChoice,\n",
    "                             RandomChoiceResize, RandomFlip)\n",
    "from mmengine.config import read_base\n",
    "from mmengine.optim.optimizer import OptimWrapper\n",
    "from mmengine.optim.scheduler.lr_scheduler import LinearLR, PolyLR\n",
    "from torch.nn.modules.batchnorm import SyncBatchNorm as SyncBN\n",
    "from torch.optim import AdamW\n",
    "from mmseg.datasets.transforms import (LoadAnnotations, PackSegInputs,\n",
    "                                       PhotoMetricDistortion, RandomCrop,\n",
    "                                       ResizeShortestEdge)\n",
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile\n",
    "from mmseg.engine.optimizers import LayerDecayOptimizerConstructor\n",
    "\n",
    "\n",
    "# EncoderDecoder\n",
    "from mmseg.models.segmentors.encoder_decoder import EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_hiera_37_encoder_decoder import ATL_Hiera_EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_multi_encoder_multi_decoder import ATL_Multi_Encoder_Multi_Decoder\n",
    "# SegDataPreProcessor\n",
    "from mmseg.models.data_preprocessor import SegDataPreProcessor\n",
    "# Backbone\n",
    "from mmseg.models.backbones import BEiTAdapter\n",
    "from mmseg.models.backbones import ViTAdapter\n",
    "# DecodeHead\n",
    "from mmseg.models.decode_heads.uper_head import UPerHead\n",
    "from mmseg.models.decode_heads.atl_hiera_37_uper_head_multi_convseg import ATL_hiera_UPerHead_Multi_convseg\n",
    "from mmseg.models.decode_heads.fcn_head import FCNHead\n",
    "# Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss import ATL_Hiera_Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss_convseg import ATL_Hiera_Loss_convseg\n",
    "from mmseg.models.losses.cross_entropy_loss import CrossEntropyLoss\n",
    "# Evaluation\n",
    "from mmseg.evaluation import IoUMetric\n",
    "\n",
    "# with read_base():\n",
    "#     from ..._base_.datasets.a_atl_0_paper_5b_GF2_19class import *\n",
    "#     from ..._base_.default_runtime import *\n",
    "#     # from ..._base_.models.upernet_beit_potsdam import *\n",
    "#     from ..._base_.schedules.schedule_80k import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_config = dict(\n",
    "            type=BEiTAdapter,\n",
    "            img_size=512,\n",
    "            patch_size=16,\n",
    "            embed_dim=768,  # B:768 L:1024\n",
    "            in_channels=3,  \n",
    "            depth=12,       # B:12 L:24\n",
    "            num_heads=12,   # B:12 L:16\n",
    "            deform_num_heads=12, # Adapter的参数： B:12 L:16\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            use_abs_pos_emb=False,\n",
    "            use_rel_pos_bias=True,\n",
    "            init_values=1e-6,\n",
    "            drop_path_rate=0.3,\n",
    "            conv_inplane=64,\n",
    "            n_points=4,\n",
    "            cffn_ratio=0.25,\n",
    "            deform_ratio=0.5,\n",
    "            with_cp=False,  # set with_cp=True to save memory\n",
    "            # interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]], # large\n",
    "            interaction_indexes=[[0, 2], [3, 5], [6, 8], [9, 11]],  # base\n",
    "            init_cfg=dict(type='Pretrained', checkpoint=pretrained) # 不加预训练权重\n",
    "        )  #backbone 完全一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cfg = dict(type=SyncBN, requires_grad=True)\n",
    "\n",
    "L1_num_classes = 5  # number of L1 Level label   # 5\n",
    "L2_num_classes = 10  # number of L1 Level label  # 11  5+11+21=37类\n",
    "L3_num_classes = 19  # number of L1 Level label  # 21\n",
    "\n",
    "\n",
    "decode_head_config=dict(\n",
    "            type=UPerHead,\n",
    "            # in_channels=[1024, 1024, 1024, 1024],  # 和vit的结构保持一致，large的话1024\n",
    "            in_channels=[768, 768, 768, 768],  # 和vit的结构保持一致，large的话1024\n",
    "            in_index=[0, 1, 2, 3],\n",
    "            pool_scales=(1, 2, 3, 6),\n",
    "            channels=768,   # 这是个 啥参数来着？\n",
    "            dropout_ratio=0.1,\n",
    "            num_classes=L3_num_classes,\n",
    "            # num_classes_level_list=[5,10,19], #37\n",
    "            norm_cfg=norm_cfg,\n",
    "            align_corners=False,\n",
    "            # loss_decode=dict(\n",
    "            #     type=ATL_Hiera_Loss_convseg, num_classes=[5,10,19], loss_weight=1.0)),\n",
    "            loss_decode=dict(\n",
    "                type=CrossEntropyLoss, use_sigmoid=False, loss_weight=1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': mmseg.models.backbones.beit_adapter.BEiTAdapter,\n",
       " 'img_size': 512,\n",
       " 'patch_size': 16,\n",
       " 'embed_dim': 768,\n",
       " 'in_channels': 4,\n",
       " 'depth': 12,\n",
       " 'num_heads': 12,\n",
       " 'deform_num_heads': 12,\n",
       " 'mlp_ratio': 4,\n",
       " 'qkv_bias': True,\n",
       " 'use_abs_pos_emb': False,\n",
       " 'use_rel_pos_bias': True,\n",
       " 'init_values': 1e-06,\n",
       " 'drop_path_rate': 0.3,\n",
       " 'conv_inplane': 64,\n",
       " 'n_points': 4,\n",
       " 'cffn_ratio': 0.25,\n",
       " 'deform_ratio': 0.5,\n",
       " 'with_cp': False,\n",
       " 'interaction_indexes': [[0, 2], [3, 5], [6, 8], [9, 11]],\n",
       " 'init_cfg': {'type': 'Pretrained',\n",
       "  'checkpoint': 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_config.update(in_channels=4)\n",
    "backbone_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': mmseg.models.backbones.beit_adapter.BEiTAdapter,\n",
       " 'img_size': 512,\n",
       " 'patch_size': 16,\n",
       " 'embed_dim': 768,\n",
       " 'in_channels': 3,\n",
       " 'depth': 12,\n",
       " 'num_heads': 12,\n",
       " 'deform_num_heads': 12,\n",
       " 'mlp_ratio': 4,\n",
       " 'qkv_bias': True,\n",
       " 'use_abs_pos_emb': False,\n",
       " 'use_rel_pos_bias': True,\n",
       " 'init_values': 1e-06,\n",
       " 'drop_path_rate': 0.3,\n",
       " 'conv_inplane': 64,\n",
       " 'n_points': 4,\n",
       " 'cffn_ratio': 0.25,\n",
       " 'deform_ratio': 0.5,\n",
       " 'with_cp': False,\n",
       " 'interaction_indexes': [[0, 2], [3, 5], [6, 8], [9, 11]],\n",
       " 'init_cfg': {'type': 'Pretrained',\n",
       "  'checkpoint': 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_MSI_3chan={**backbone_config, 'in_channels': 3}\n",
    "backbone_MSI_3chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': mmseg.models.backbones.beit_adapter.BEiTAdapter,\n",
       " 'img_size': 512,\n",
       " 'patch_size': 16,\n",
       " 'embed_dim': 768,\n",
       " 'in_channels': 4,\n",
       " 'depth': 12,\n",
       " 'num_heads': 12,\n",
       " 'deform_num_heads': 12,\n",
       " 'mlp_ratio': 4,\n",
       " 'qkv_bias': True,\n",
       " 'use_abs_pos_emb': False,\n",
       " 'use_rel_pos_bias': True,\n",
       " 'init_values': 1e-06,\n",
       " 'drop_path_rate': 0.3,\n",
       " 'conv_inplane': 64,\n",
       " 'n_points': 4,\n",
       " 'cffn_ratio': 0.25,\n",
       " 'deform_ratio': 0.5,\n",
       " 'with_cp': False,\n",
       " 'interaction_indexes': [[0, 2], [3, 5], [6, 8], [9, 11]],\n",
       " 'init_cfg': {'type': 'Pretrained',\n",
       "  'checkpoint': 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_MSI_3chan={**backbone_config, 'in_channels': 4}\n",
    "backbone_MSI_3chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dict() got multiple values for keyword argument 'in_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m backbone_MSI_3chan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackbone_config, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 打印更新后的字典\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(backbone_MSI_3chan)\n",
      "\u001b[0;31mTypeError\u001b[0m: dict() got multiple values for keyword argument 'in_channels'"
     ]
    }
   ],
   "source": [
    "backbone_MSI_3chan = dict(**backbone_config, in_channels=10)\n",
    "\n",
    "# 打印更新后的字典\n",
    "print(backbone_MSI_3chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "backbone_MSI_3chan=\n",
    "print(backbone_MSI_3chan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atl-py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
