{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# 2024-09-02 测试, 可以跑通,loss-从5开始降低。\n",
    "import torch\n",
    "from mmcv.transforms import (LoadImageFromFile, RandomChoice,\n",
    "                             RandomChoiceResize, RandomFlip)\n",
    "from mmengine.config import read_base\n",
    "from mmengine.optim.optimizer import OptimWrapper\n",
    "from mmengine.optim.scheduler.lr_scheduler import LinearLR, PolyLR\n",
    "from torch.nn.modules.batchnorm import SyncBatchNorm as SyncBN\n",
    "from torch.optim import AdamW\n",
    "from mmseg.datasets.transforms import (LoadAnnotations, PackSegInputs,\n",
    "                                       PhotoMetricDistortion, RandomCrop,\n",
    "                                       ResizeShortestEdge)\n",
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile\n",
    "from mmseg.engine.optimizers.layer_decay_optimizer_constructor import ATL_LayerDecayOptimizerConstructor\n",
    "from mmseg.engine.optimizers import LayerDecayOptimizerConstructor\n",
    "\n",
    "\n",
    "# EncoderDecoder\n",
    "from mmseg.models.segmentors.encoder_decoder import EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_hiera_37_encoder_decoder import ATL_Hiera_EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_multi_encoder_multi_decoder import ATL_Multi_Encoder_Multi_Decoder\n",
    "from mmseg.models.segmentors.atl_multi_encoder_multi_decoder_cfglist import ATL_Multi_Encoder_Multi_Decoder_cfglist\n",
    "# SegDataPreProcessor\n",
    "from mmseg.models.data_preprocessor import SegDataPreProcessor\n",
    "from mmseg.models.data_preprocessor_atl import ATL_SegDataPreProcessor\n",
    "# Backbone\n",
    "from mmseg.models.backbones import BEiTAdapter\n",
    "from mmseg.models.backbones import ViTAdapter\n",
    "# DecodeHead\n",
    "from mmseg.models.decode_heads.uper_head import UPerHead\n",
    "from mmseg.models.decode_heads.atl_hiera_37_uper_head_multi_convseg import ATL_hiera_UPerHead_Multi_convseg\n",
    "from mmseg.models.decode_heads.atl_multi_encoder_multi_decoder_uperhead import ATL_Multi_Encoder_Multi_Decoder_UPerHead\n",
    "from mmseg.models.decode_heads.atl_fcn_head_multi_embedding import ATL_multi_embedding_FCNHead\n",
    "from mmseg.models.decode_heads.fcn_head import FCNHead\n",
    "# Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss import ATL_Hiera_Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss_convseg import ATL_Hiera_Loss_convseg\n",
    "from mmseg.models.losses.cross_entropy_loss import CrossEntropyLoss\n",
    "# Evaluation\n",
    "from mmseg.evaluation import IoUMetric\n",
    "\n",
    "# with read_base():\n",
    "#     # from ..._base_.datasets.a_atl_0_paper_multi_GF2_Google_S2_19class import *\n",
    "#     from ..._base_.datasets.atl_0_paper_crop_10m_s2_4class import *\n",
    "#     from ..._base_.default_runtime import *\n",
    "#     # from ..._base_.models.upernet_beit_potsdam import *\n",
    "#     from ..._base_.schedules.schedule_80k import *\n",
    "\n",
    "find_unuser_parameters = False\n",
    "\n",
    "# 一定记得改类别数！！！！！！！！！！！！！！！！！！！！！！！\n",
    "norm_cfg = dict(type=SyncBN, requires_grad=True)\n",
    "\n",
    "base_L1_num_classes = 5  # number of L1 Level label   # 5\n",
    "base_L2_num_classes = 10  # number of L1 Level label  # 11  5+11+21=37类\n",
    "base_L3_num_classes = 4  # number of L1 Level label  # 21\n",
    "\n",
    "\n",
    "downstream_L1_num_classes = 2  # number of L1 Level label  # 农田 / 非农田  # 来自于base domain的 mask\n",
    "downstream_L2_num_classes = 3  # number of L1 Level label  # 目标作物农田——非目标作物农田(base的mask基础上) / 非农田 （base）\n",
    "downstream_L3_num_classes = 4  # number of L1 Level label  # 水稻 大豆 玉米 / 其他\n",
    "# 总的类别数，包括背景，L1+L2+L3级标签数\n",
    "\n",
    "# 这和后面base的模型不一样的话，如果在decode_head里，给这三个数赋值的话，会报非常难定的错误\n",
    "crop_size = (512, 512)\n",
    "pretrained_3chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-3chan.pth'\n",
    "pretrained_4chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'\n",
    "pretrained_10chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-10chan.pth'\n",
    "\n",
    "data_preprocessor = dict(\n",
    "        type=ATL_SegDataPreProcessor,\n",
    "        mean = None,\n",
    "        std = None,\n",
    "        pad_val=0,\n",
    "        seg_pad_val=255,\n",
    "        size=crop_size)\n",
    "\n",
    "# Encoder Config\n",
    "backbone_config = dict(\n",
    "        type=BEiTAdapter,\n",
    "        img_size=512,\n",
    "        patch_size=16,\n",
    "        embed_dim=1024,  # B:768 L:1024\n",
    "        in_channels=3,  \n",
    "        depth=24,       # B:12 L:24\n",
    "        num_heads=16,   # B:12 L:16\n",
    "        deform_num_heads=16, # Adapter的参数： B:12 L:16\n",
    "        mlp_ratio=4,\n",
    "        qkv_bias=True,\n",
    "        use_abs_pos_emb=False,\n",
    "        use_rel_pos_bias=True,\n",
    "        init_values=1e-6,\n",
    "        drop_path_rate=0.3,\n",
    "        conv_inplane=64,\n",
    "        n_points=4,\n",
    "        cffn_ratio=0.25,\n",
    "        deform_ratio=0.5,\n",
    "        with_cp=False,  # set with_cp=True to save memory\n",
    "        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]], # large\n",
    "        # interaction_indexes=[[0, 2], [3, 5], [6, 8], [9, 11]],  # base\n",
    "        init_cfg=dict(type='Pretrained', checkpoint=pretrained_3chan)) # 不加预训练权重\n",
    "\n",
    "# Decoder Config\n",
    "decode_head_config=dict(\n",
    "        type=ATL_Multi_Encoder_Multi_Decoder_UPerHead,\n",
    "        in_channels=[1024, 1024, 1024, 1024],  # 和vit的结构保持一致，large的话1024\n",
    "        # in_channels=[768, 768, 768, 768],  # 和vit的结构保持一致，large的话1024\n",
    "        in_index=[0, 1, 2, 3],\n",
    "        pool_scales=(1, 2, 3, 6),\n",
    "        channels=1024,   # 768  1024 这是个 啥参数来着？\n",
    "        dropout_ratio=0.1,\n",
    "        num_classes=base_L3_num_classes,\n",
    "        # num_classes_level_list=[5,10,19], #37\n",
    "        norm_cfg=norm_cfg,\n",
    "        align_corners=False,\n",
    "        # loss_decode=dict(\n",
    "        #     type=ATL_Hiera_Loss_convseg, num_classes=[5,10,19], loss_weight=1.0)),\n",
    "        loss_decode=dict(\n",
    "            type=CrossEntropyLoss, use_sigmoid=False, loss_weight=1.0))\n",
    "\n",
    "\n",
    "# backbone config\n",
    "backbone_MSI_3chan={**backbone_config, 'in_channels': 3, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_3chan)}\n",
    "backbone_MSI_4chan={**backbone_config, 'in_channels': 4, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_4chan)}\n",
    "backbone_MSI_10chan={**backbone_config, 'in_channels': 10, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_10chan)}\n",
    "\n",
    "# decode_head_config\n",
    "decode_head_MSI_3chan=decode_head_config\n",
    "decode_head_MSI_4chan=decode_head_config\n",
    "decode_head_MSI_10chan=decode_head_config\n",
    "decode_head_10chan_crop10m={**decode_head_config, 'num_classes': downstream_L3_num_classes}\n",
    "\n",
    "print(type(decode_head_MSI_3chan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_config_base_list=dict(backbone_MSI_3chan=backbone_MSI_3chan,\n",
    "                                backbone_MSI_4chan=backbone_MSI_4chan,\n",
    "                                backbone_MSI_10chan=backbone_MSI_10chan)\n",
    "# decode_head 3个 全冻结\n",
    "decode_head_config_base_list=dict(decode_head_MSI_3chan=decode_head_MSI_3chan,\n",
    "                                    decode_head_MSI_4chan=decode_head_MSI_4chan,\n",
    "                                    decode_head_MSI_10chan=decode_head_MSI_10chan)\n",
    "\n",
    "\n",
    "# 只有这个有梯度 \n",
    "decode_head_config_downstream = decode_head_10chan_crop10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to f-string expression here. Maybe you meant '==' instead of '='? (3528014694.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    f'{backbone_name}' = MODELS.build(backbone_config_base_list[backbone_name])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to f-string expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "from mmseg.registry import MODELS\n",
    "for _, backbone_name in enumerate(backbone_config_base_list):\n",
    "    # print(type(backbone_config_base_list[backbone_name]))\n",
    "    f'{backbone_name}' = MODELS.build(backbone_config_base_list[backbone_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-09-02 测试, 可以跑通,loss-从5开始降低。\n",
    "\n",
    "from mmcv.transforms import (LoadImageFromFile, RandomChoice,\n",
    "                             RandomChoiceResize, RandomFlip)\n",
    "from mmengine.config import read_base\n",
    "from mmengine.optim.optimizer import OptimWrapper\n",
    "from mmengine.optim.scheduler.lr_scheduler import LinearLR, PolyLR\n",
    "from torch.nn.modules.batchnorm import SyncBatchNorm as SyncBN\n",
    "from torch.optim import AdamW\n",
    "from mmseg.datasets.transforms import (LoadAnnotations, PackSegInputs,\n",
    "                                       PhotoMetricDistortion, RandomCrop,\n",
    "                                       ResizeShortestEdge)\n",
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile\n",
    "from mmseg.engine.optimizers.layer_decay_optimizer_constructor import ATL_LayerDecayOptimizerConstructor\n",
    "from mmseg.engine.optimizers import LayerDecayOptimizerConstructor\n",
    "\n",
    "\n",
    "# EncoderDecoder\n",
    "from mmseg.models.segmentors.encoder_decoder import EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_hiera_37_encoder_decoder import ATL_Hiera_EncoderDecoder\n",
    "from mmseg.models.segmentors.atl_multi_encoder_multi_decoder import ATL_Multi_Encoder_Multi_Decoder\n",
    "from mmseg.models.segmentors.atl_multi_encoder_multi_decoder_cfglist import ATL_Multi_Encoder_Multi_Decoder_cfglist\n",
    "# SegDataPreProcessor\n",
    "from mmseg.models.data_preprocessor import SegDataPreProcessor\n",
    "from mmseg.models.data_preprocessor_atl import ATL_SegDataPreProcessor\n",
    "# Backbone\n",
    "from mmseg.models.backbones import BEiTAdapter\n",
    "from mmseg.models.backbones import ViTAdapter\n",
    "# DecodeHead\n",
    "from mmseg.models.decode_heads.uper_head import UPerHead\n",
    "from mmseg.models.decode_heads.atl_hiera_37_uper_head_multi_convseg import ATL_hiera_UPerHead_Multi_convseg\n",
    "from mmseg.models.decode_heads.atl_multi_encoder_multi_decoder_uperhead import ATL_Multi_Encoder_Multi_Decoder_UPerHead\n",
    "from mmseg.models.decode_heads.atl_fcn_head_multi_embedding import ATL_multi_embedding_FCNHead\n",
    "from mmseg.models.decode_heads.fcn_head import FCNHead\n",
    "# Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss import ATL_Hiera_Loss\n",
    "from mmseg.models.losses.atl_hiera_37_loss_convseg import ATL_Hiera_Loss_convseg\n",
    "from mmseg.models.losses.cross_entropy_loss import CrossEntropyLoss\n",
    "# Evaluation\n",
    "from mmseg.evaluation import IoUMetric\n",
    "\n",
    "# with read_base():\n",
    "#     # from ..._base_.datasets.a_atl_0_paper_multi_GF2_Google_S2_19class import *\n",
    "#     from ..._base_.datasets.atl_0_paper_crop_10m_s2_4class import *\n",
    "#     from ..._base_.default_runtime import *\n",
    "#     # from ..._base_.models.upernet_beit_potsdam import *\n",
    "#     from ..._base_.schedules.schedule_80k import *\n",
    "\n",
    "find_unuser_parameters = False\n",
    "\n",
    "# 一定记得改类别数！！！！！！！！！！！！！！！！！！！！！！！\n",
    "norm_cfg = dict(type=SyncBN, requires_grad=True)\n",
    "\n",
    "base_L1_num_classes = 5  # number of L1 Level label   # 5\n",
    "base_L2_num_classes = 10  # number of L1 Level label  # 11  5+11+21=37类\n",
    "base_L3_num_classes = 4  # number of L1 Level label  # 21\n",
    "\n",
    "\n",
    "downstream_L1_num_classes = 2  # number of L1 Level label  # 农田 / 非农田  # 来自于base domain的 mask\n",
    "downstream_L2_num_classes = 3  # number of L1 Level label  # 目标作物农田——非目标作物农田(base的mask基础上) / 非农田 （base）\n",
    "downstream_L3_num_classes = 4  # number of L1 Level label  # 水稻 大豆 玉米 / 其他\n",
    "# 总的类别数，包括背景，L1+L2+L3级标签数\n",
    "\n",
    "# 这和后面base的模型不一样的话，如果在decode_head里，给这三个数赋值的话，会报非常难定的错误\n",
    "crop_size = (512, 512)\n",
    "pretrained_3chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-3chan.pth'\n",
    "pretrained_4chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-4chan.pth'\n",
    "pretrained_10chan = 'checkpoints/2-对比实验的权重/vit-adapter-offical/BEiT/beitv2_large_patch16_224_pt1k_ft21k-10chan.pth'\n",
    "\n",
    "data_preprocessor = dict(\n",
    "        type=ATL_SegDataPreProcessor,\n",
    "        mean = None,\n",
    "        std = None,\n",
    "        pad_val=0,\n",
    "        seg_pad_val=255,\n",
    "        size=crop_size)\n",
    "\n",
    "# Encoder Config\n",
    "backbone_config = dict(\n",
    "        type=BEiTAdapter,\n",
    "        img_size=512,\n",
    "        patch_size=16,\n",
    "        embed_dim=1024,  # B:768 L:1024\n",
    "        in_channels=3,  \n",
    "        depth=24,       # B:12 L:24\n",
    "        num_heads=16,   # B:12 L:16\n",
    "        deform_num_heads=16, # Adapter的参数： B:12 L:16\n",
    "        mlp_ratio=4,\n",
    "        qkv_bias=True,\n",
    "        use_abs_pos_emb=False,\n",
    "        use_rel_pos_bias=True,\n",
    "        init_values=1e-6,\n",
    "        drop_path_rate=0.3,\n",
    "        conv_inplane=64,\n",
    "        n_points=4,\n",
    "        cffn_ratio=0.25,\n",
    "        deform_ratio=0.5,\n",
    "        with_cp=False,  # set with_cp=True to save memory\n",
    "        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]], # large\n",
    "        # interaction_indexes=[[0, 2], [3, 5], [6, 8], [9, 11]],  # base\n",
    "        init_cfg=dict(type='Pretrained', checkpoint=pretrained_3chan)) # 不加预训练权重\n",
    "\n",
    "# Decoder Config\n",
    "decode_head_config=dict(\n",
    "        type=ATL_Multi_Encoder_Multi_Decoder_UPerHead,\n",
    "        in_channels=[1024, 1024, 1024, 1024],  # 和vit的结构保持一致，large的话1024\n",
    "        # in_channels=[768, 768, 768, 768],  # 和vit的结构保持一致，large的话1024\n",
    "        in_index=[0, 1, 2, 3],\n",
    "        pool_scales=(1, 2, 3, 6),\n",
    "        channels=1024,   # 768  1024 这是个 啥参数来着？\n",
    "        dropout_ratio=0.1,\n",
    "        num_classes=base_L3_num_classes,\n",
    "        # num_classes_level_list=[5,10,19], #37\n",
    "        norm_cfg=norm_cfg,\n",
    "        align_corners=False,\n",
    "        # loss_decode=dict(\n",
    "        #     type=ATL_Hiera_Loss_convseg, num_classes=[5,10,19], loss_weight=1.0)),\n",
    "        loss_decode=dict(\n",
    "            type=CrossEntropyLoss, use_sigmoid=False, loss_weight=1.0))\n",
    "\n",
    "\n",
    "# backbone config\n",
    "backbone_MSI_3chan={**backbone_config, 'in_channels': 3, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_3chan)}\n",
    "backbone_MSI_4chan={**backbone_config, 'in_channels': 4, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_4chan)}\n",
    "backbone_MSI_10chan={**backbone_config, 'in_channels': 10, 'init_cfg': dict(type='Pretrained', checkpoint=pretrained_10chan)}\n",
    "\n",
    "# decode_head_config\n",
    "decode_head_MSI_3chan=decode_head_config\n",
    "decode_head_MSI_4chan=decode_head_config\n",
    "decode_head_MSI_10chan=decode_head_config\n",
    "decode_head_10chan_crop10m={**decode_head_config, 'num_classes': downstream_L3_num_classes}\n",
    "\n",
    "model=dict(\n",
    "        type=ATL_Multi_Encoder_Multi_Decoder_cfglist,\n",
    "        data_preprocessor=data_preprocessor,\n",
    "\n",
    "        # backbone 3个   全冻结\n",
    "        backbone_config_base_list=dict(backbone_MSI_3chan=backbone_MSI_3chan,\n",
    "                                       backbone_MSI_4chan=backbone_MSI_4chan,\n",
    "                                       backbone_MSI_10chan=backbone_MSI_10chan),\n",
    "        # decode_head 3个 全冻结\n",
    "        decode_head_config_base_list=dict(decode_head_MSI_3chan=decode_head_MSI_3chan,\n",
    "                                          decode_head_MSI_4chan=decode_head_MSI_4chan,\n",
    "                                          decode_head_MSI_10chan=decode_head_MSI_10chan), \n",
    "\n",
    "        # 只有这个有梯度 \n",
    "        decode_head_config_downstream = decode_head_10chan_crop10m,\n",
    "\n",
    "        auxiliary_head=dict(\n",
    "            type=ATL_multi_embedding_FCNHead,\n",
    "            in_channels=1024, # 和上面的768 保持统一\n",
    "            in_index=3,\n",
    "            channels=256,\n",
    "            num_convs=1,\n",
    "            concat_input=False,\n",
    "            dropout_ratio=0.1,\n",
    "            num_classes=downstream_L3_num_classes, #21\n",
    "            norm_cfg=norm_cfg,\n",
    "            align_corners=False,\n",
    "            loss_decode=dict(\n",
    "                type=CrossEntropyLoss, use_sigmoid=False, loss_weight=0.4)),\n",
    "        test_cfg=dict(mode='whole'))\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = dict(\n",
    "    type=AdamW,\n",
    "    lr=2e-5,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.05,\n",
    ")\n",
    "optim_wrapper = dict(\n",
    "    type=OptimWrapper,\n",
    "    optimizer=optimizer,\n",
    "    constructor=ATL_LayerDecayOptimizerConstructor,\n",
    "    paramwise_cfg=dict(num_layers=12, layer_decay_rate=0.9))\n",
    "\n",
    "\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(type=LinearLR, start_factor=1e-6, by_epoch=False, begin=0, end=1500),\n",
    "    dict(\n",
    "        type=PolyLR,\n",
    "        power=1.0,\n",
    "        begin=1500,\n",
    "        # begin=0,\n",
    "        end=80000,\n",
    "        eta_min=0.0,\n",
    "        by_epoch=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "val_evaluator = dict(\n",
    "    type=IoUMetric, iou_metrics=['mIoU', 'mFscore'])  # 'mDice', 'mFscore'\n",
    "test_evaluator = dict(\n",
    "    type=IoUMetric,\n",
    "    iou_metrics=['mIoU', 'mFscore'],\n",
    "    # format_only=True,\n",
    "    keep_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'backbone_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mATL_Multi_Encoder_Multi_Decoder_cfglist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone_config_base_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_head_config_base_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/AI-Tianlong/openmmlab/mmsegmentation/mmseg/models/segmentors/atl_multi_encoder_multi_decoder_cfglist.py:107\u001b[0m, in \u001b[0;36mATL_Multi_Encoder_Multi_Decoder_cfglist.__init__\u001b[0;34m(self, backbone_config_base_list, decode_head_config_base_list, neck, auxiliary_head, train_cfg, test_cfg, data_preprocessor, pretrained, init_cfg)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(backbone_config_base_list, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease check the backbone_config_base_list, expect dict, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(backbone_config_base_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, backbone_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(backbone_config_base_list):\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;66;03m# 创建 self.backbone_MSI_3chan, self.backbone_MSI_4chan, self.backbone_MSI_10chan\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, backbone_name, MODELS\u001b[38;5;241m.\u001b[39mbuild(backbone_config_base_list[backbone_name]))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Build ,Multi decode_head \u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(decode_head_config_base_list, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'backbone_config'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atl-py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
