{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.registry import init_default_scope\n",
    "from mmcv.transforms.loading import LoadImageFromFile\n",
    "from mmcv.transforms.processing import (RandomFlip, RandomResize, Resize,\n",
    "                                        TestTimeAug)\n",
    "from mmengine.dataset.sampler import DefaultSampler, InfiniteSampler\n",
    "\n",
    "from mmseg.datasets.atl_0_paper_new_5b_GF_Google_S2_19class import ATL_5B_GF_Google_S2_Dataset_19class\n",
    "from mmseg.datasets.transforms.formatting import PackSegInputs\n",
    "from mmseg.datasets.transforms.loading import (LoadAnnotations,\n",
    "                                               LoadSingleRSImageFromFile)\n",
    "from mmseg.datasets.transforms.transforms import (PhotoMetricDistortion,\n",
    "                                                  RandomCrop)\n",
    "from mmseg.evaluation import IoUMetric\n",
    "\n",
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile_with_data_preproocess\n",
    "\n",
    "init_default_scope('mmseg')\n",
    "\n",
    "data_root = '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512'\n",
    "data_prefix=dict(img_path='img_dir/train/GF2_5B_19类_size512', seg_map_path='ann_dir/train/GF2_5B_19类_size512')\n",
    "train_pipeline = [\n",
    "    dict(type=LoadSingleRSImageFromFile_with_data_preproocess),\n",
    "    dict(type=LoadAnnotations),\n",
    "    dict(type=RandomCrop, crop_size=(512, 512), cat_max_ratio=0.75),\n",
    "    dict(type=RandomFlip, prob=0.5),\n",
    "    dict(type=PackSegInputs)\n",
    "]\n",
    "\n",
    "dataset = ATL_5B_GF_Google_S2_Dataset_19class(data_root=data_root, data_prefix=data_prefix, test_mode=False, pipeline=train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_path': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_0.tif', 'seg_map_path': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_0.tif', 'label_map': None, 'reduce_zero_label': True, 'seg_fields': [], 'sample_idx': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_data_info(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': ('Paddy field', 'Other Field', 'Forest', 'Natural meadow', 'Artificial meadow', 'River', 'Lake', 'Pond', 'Factory-Storage-Shopping malls', 'Urban residential', 'Rural residential', 'Stadium', 'Park Square', 'Road', 'Overpass', 'Railway station', 'Airport', 'Bare land', 'Glaciers Snow'), 'palette': [[0, 240, 150], [150, 250, 0], [0, 150, 0], [250, 200, 0], [200, 200, 0], [0, 0, 200], [0, 150, 200], [150, 200, 250], [200, 0, 0], [250, 0, 150], [200, 150, 150], [250, 200, 150], [150, 150, 0], [250, 150, 150], [250, 150, 0], [250, 200, 250], [200, 150, 0], [200, 100, 50], [255, 255, 255]], 'label_map': None, 'reduce_zero_label': True}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': tensor([[[405., 400., 396.,  ..., 436., 439., 458.],\n",
       "          [410., 409., 402.,  ..., 431., 436., 448.],\n",
       "          [402., 408., 405.,  ..., 429., 433., 442.],\n",
       "          ...,\n",
       "          [412., 410., 407.,  ..., 403., 407., 417.],\n",
       "          [412., 410., 407.,  ..., 397., 402., 416.],\n",
       "          [412., 409., 406.,  ..., 398., 399., 413.]],\n",
       " \n",
       "         [[296., 284., 275.,  ..., 333., 334., 344.],\n",
       "          [307., 305., 289.,  ..., 327., 333., 335.],\n",
       "          [291., 303., 299.,  ..., 327., 332., 332.],\n",
       "          ...,\n",
       "          [301., 293., 288.,  ..., 273., 280., 293.],\n",
       "          [301., 293., 287.,  ..., 260., 273., 293.],\n",
       "          [296., 292., 286.,  ..., 260., 266., 289.]],\n",
       " \n",
       "         [[292., 271., 251.,  ..., 330., 334., 330.],\n",
       "          [304., 302., 275.,  ..., 325., 333., 328.],\n",
       "          [275., 294., 285.,  ..., 324., 332., 328.],\n",
       "          ...,\n",
       "          [340., 321., 309.,  ..., 235., 247., 264.],\n",
       "          [340., 324., 311.,  ..., 222., 240., 264.],\n",
       "          [334., 325., 311.,  ..., 218., 229., 259.]],\n",
       " \n",
       "         [[226., 197., 178.,  ..., 250., 253., 246.],\n",
       "          [245., 234., 201.,  ..., 247., 254., 248.],\n",
       "          [225., 238., 222.,  ..., 246., 253., 247.],\n",
       "          ...,\n",
       "          [255., 241., 230.,  ..., 194., 211., 229.],\n",
       "          [254., 242., 231.,  ..., 176., 196., 225.],\n",
       "          [251., 243., 232.,  ..., 173., 181., 215.]]]),\n",
       " 'data_samples': <SegDataSample(\n",
       " \n",
       "     META INFORMATION\n",
       "     flip: True\n",
       "     img_shape: (512, 512)\n",
       "     reduce_zero_label: True\n",
       "     flip_direction: 'horizontal'\n",
       "     ori_shape: (512, 512)\n",
       "     img_path: '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_1.tif'\n",
       "     seg_map_path: '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_1.tif'\n",
       " \n",
       "     DATA FIELDS\n",
       "     gt_sem_seg: <PixelData(\n",
       "         \n",
       "             META INFORMATION\n",
       "         \n",
       "             DATA FIELDS\n",
       "             data: tensor([[[255, 255, 255,  ..., 255, 255, 255],\n",
       "                          [255, 255, 255,  ..., 255, 255, 255],\n",
       "                          [255, 255, 255,  ..., 255, 255, 255],\n",
       "                          ...,\n",
       "                          [ 17,  17,  17,  ...,   1,   1,   1],\n",
       "                          [ 17,  17,  17,  ...,   1,   1,   1],\n",
       "                          [ 17,  17,  17,  ...,   1,   1,   1]]])\n",
       "         ) at 0x79a53930c4c0>\n",
       " ) at 0x79a55b5492d0>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = dataset[0]['inputs']  # 4 512 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.registry import init_default_scope\n",
    "from mmcv.transforms.loading import LoadImageFromFile\n",
    "from mmcv.transforms.processing import (RandomFlip, RandomResize, Resize,\n",
    "                                        TestTimeAug)\n",
    "from mmengine.dataset.sampler import DefaultSampler, InfiniteSampler\n",
    "\n",
    "from mmseg.datasets.atl_0_paper_new_5b_GF_Google_S2_19class import ATL_5B_GF_Google_S2_Dataset_19class\n",
    "from mmseg.datasets.transforms.formatting import PackSegInputs, ATL_3_embedding_PackSegInputs\n",
    "from mmseg.datasets.transforms.loading import (LoadAnnotations,\n",
    "                                               LoadSingleRSImageFromFile)\n",
    "from mmseg.datasets.transforms.transforms import (PhotoMetricDistortion,\n",
    "                                                  RandomCrop)\n",
    "\n",
    "\n",
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile_with_data_preproocess, ATL_multi_embedding_LoadAnnotations\n",
    "\n",
    "\n",
    "\n",
    "init_default_scope('mmseg')\n",
    "\n",
    "data_root = '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512'\n",
    "data_prefix=dict(\n",
    "    # img_path='img_dir/train/Google_5B_19类_size512', seg_map_path='ann_dir/train/Google_5B_19类_size512'), # 3chan\n",
    "    img_path_MSI_4chan='img_dir/train/GF2_5B_19类_size512',         # 4chan GF2\n",
    "    img_path_MSI_10chan='img_dir/train/S2_5B_19类_包含雪_size512',   # 10chan S2\n",
    "    \n",
    "    seg_map_path_MSI_4chan='ann_dir/train/GF2_5B_19类_size512',     # 4chan\n",
    "    seg_map_path_MSI_10chan='ann_dir/train/S2_5B_19类_包含雪_size512')   # 10chan\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type=LoadSingleRSImageFromFile_with_data_preproocess),\n",
    "    dict(type=ATL_multi_embedding_LoadAnnotations),\n",
    "    dict(type=ATL_3_embedding_PackSegInputs)\n",
    "]\n",
    "\n",
    "dataset = ATL_5B_GF_Google_S2_Dataset_19class(data_root=data_root, data_prefix=data_prefix, test_mode=False, pipeline=train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mmseg.datasets.atl_0_paper_new_5b_GF_Google_S2_19class.ATL_5B_GF_Google_S2_Dataset_19class at 0x7594ba7f0910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path_MIS_4chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_0.tif',\n",
       " 'img_path_MIS_10chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/S2_5B_19类_包含雪_size512/train/S2_SR_2019_GF2_PMS2__L1A0001824765-MSS2_4_4.tif',\n",
       " 'seg_map_path_MIS_4chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_0.tif',\n",
       " 'seg_map_path_MIS_10chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/S2_5B_19类_包含雪_size512/train/S2_SR_2019_GF2_PMS2__L1A0001824765-MSS2_4_4.tif',\n",
       " 'label_map': None,\n",
       " 'reduce_zero_label': True,\n",
       " 'seg_fields': [],\n",
       " 'sample_idx': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_data_info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path_MIS_4chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_10_1.tif',\n",
       " 'img_path_MIS_10chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/S2_5B_19类_包含雪_size512/train/S2_SR_2019_GF2_PMS2__L1A0001251799-MSS2_2_0.tif',\n",
       " 'seg_map_path_MIS_4chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_10_1.tif',\n",
       " 'seg_map_path_MIS_10chan': '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/ann_dir/train/S2_5B_19类_包含雪_size512/train/S2_SR_2019_GF2_PMS2__L1A0001251799-MSS2_2_0.tif',\n",
       " 'label_map': None,\n",
       " 'reduce_zero_label': True,\n",
       " 'seg_fields': [],\n",
       " 'sample_idx': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_data_info(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ATL_5B_GF_Google_S2_Dataset_19class' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ATL_5B_GF_Google_S2_Dataset_19class' object is not an iterator"
     ]
    }
   ],
   "source": [
    "data=  next(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 Normliazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.transforms.loading import LoadSingleRSImageFromFile_with_data_preproocess\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_load_img(results):    \n",
    "    filename_MSI_4chan = results['img_path_MIS_4chan']\n",
    "    filename_MSI_10chan = results['img_path_MIS_10chan']\n",
    "    ds_MSI_4chan = gdal.Open(filename_MSI_4chan)\n",
    "    ds_MSI_10chan = gdal.Open(filename_MSI_10chan)\n",
    "    # img_array = ds.ReadAsArray()\n",
    "    # print(f'【ATL-LOG-LoadSingleRSImageFromFile】filename:{filename} img_array.shape {img_array.shape}')\n",
    "    if ds_MSI_4chan is None:\n",
    "        raise Exception(f'Unable to open file: {ds_MSI_4chan}')\n",
    "    if ds_MSI_10chan is None:\n",
    "        raise Exception(f'Unable to open file: {ds_MSI_4chan}')\n",
    "    img_MSI_4chan = np.einsum('ijk->jki', ds_MSI_4chan.ReadAsArray())  # 这句报错，说\n",
    "    img_MSI_10chan = np.einsum('ijk->jki', ds_MSI_10chan.ReadAsArray())\n",
    "\n",
    "\n",
    "    img_MSI_4chan = np.nan_to_num(img_MSI_4chan, nan=0)\n",
    "    img_MSI_10chan = np.nan_to_num(img_MSI_10chan, nan=0)\n",
    "\n",
    "\n",
    "    if True:\n",
    "        img_MSI_4chan = img_MSI_4chan.astype(np.float32)\n",
    "        img_MSI_10chan = img_MSI_10chan.astype(np.float32)\n",
    "\n",
    "    if True:\n",
    "        RGB_3chan_mean = [123.675, 116.28, 103.53]\n",
    "        RGB_3chan_std = [58.395, 57.12, 57.375]\n",
    "        MSI_4chan_mean =[454.1608733420, 320.6480230485 , 238.9676917808 , 301.4478970428]\n",
    "        MSI_4chan_std =[55.4731833972, 51.5171917858, 62.3875607521, 82.6082214602]\n",
    "\n",
    "        if img_MSI_4chan.shape[2] == 4:\n",
    "            img_MSI_4chan_valid = img_MSI_4chan!=0 \n",
    "            print(img_MSI_4chan_valid.shape) # 512 512 4\n",
    "            # img_MSI_4chan[img_MSI_4chan_valid] = (img_MSI_4chan- MSI_4chan_mean) / MSI_4chan_std\n",
    "        \n",
    "        if img_MSI_10chan.shape[2] == 10:\n",
    "            img_MSI_10chan = img_MSI_10chan # S2 MSI 10通道的图像不需要归一化\n",
    "\n",
    "\n",
    "    results['img_MSI_4chan'] = img_MSI_4chan\n",
    "    results['img_MSI_10chan'] = img_MSI_10chan\n",
    "    results['img_shape'] = img_MSI_4chan.shape[:2]\n",
    "    results['ori_shape'] = img_MSI_4chan.shape[:2]\n",
    "    # print(f\"img.shape {results['img'].shape}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=dict()\n",
    "img_MSI_10_path = '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/S2_5B_19类_包含雪_size512/train/S2_SR_2019_GF2_PMS1__L1A0001798942-MSS1_3_4.tif'\n",
    "img_MSI_4_path = '/data/AI-Tianlong/openmmlab/mmsegmentation/data/1-paper-segmentation/2-多领域地物覆盖基础/0-seg-裁切好的训练图像_S2_GF2_Google_size512/img_dir/train/GF2_5B_19类_size512/train/GF2_PMS1__L1A0000564539-MSS1_0_0.tif'\n",
    "\n",
    "results['img_path_MIS_4chan'] = img_MSI_4_path\n",
    "results['img_path_MIS_10chan'] = img_MSI_10_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_MSI_4chan = results['img_path_MIS_4chan']\n",
    "filename_MSI_10chan = results['img_path_MIS_10chan']\n",
    "ds_MSI_4chan = gdal.Open(filename_MSI_4chan)\n",
    "ds_MSI_10chan = gdal.Open(filename_MSI_10chan)\n",
    "# img_array = ds.ReadAsArray()\n",
    "# print(f'【ATL-LOG-LoadSingleRSImageFromFile】filename:{filename} img_array.shape {img_array.shape}')\n",
    "if ds_MSI_4chan is None:\n",
    "    raise Exception(f'Unable to open file: {ds_MSI_4chan}')\n",
    "if ds_MSI_10chan is None:\n",
    "    raise Exception(f'Unable to open file: {ds_MSI_4chan}')\n",
    "img_MSI_4chan = np.einsum('ijk->jki', ds_MSI_4chan.ReadAsArray())  # 这句报错，说\n",
    "img_MSI_10chan = np.einsum('ijk->jki', ds_MSI_10chan.ReadAsArray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSI_4chan_mean =[454.1608733420, 320.6480230485 , 238.9676917808 , 301.4478970428]\n",
    "MSI_4chan_std =[55.4731833972, 51.5171917858, 62.3875607521, 82.6082214602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[393, 275, 281, 206],\n",
       "        [396, 278, 280, 205],\n",
       "        [398, 278, 280, 207],\n",
       "        ...,\n",
       "        [479, 362, 321, 225],\n",
       "        [485, 368, 332, 238],\n",
       "        [480, 363, 331, 242]],\n",
       "\n",
       "       [[396, 276, 283, 207],\n",
       "        [396, 280, 283, 207],\n",
       "        [397, 281, 282, 208],\n",
       "        ...,\n",
       "        [481, 361, 323, 227],\n",
       "        [484, 366, 331, 238],\n",
       "        [470, 353, 327, 241]],\n",
       "\n",
       "       [[399, 280, 283, 207],\n",
       "        [397, 283, 284, 208],\n",
       "        [399, 282, 285, 210],\n",
       "        ...,\n",
       "        [471, 347, 312, 220],\n",
       "        [472, 350, 317, 225],\n",
       "        [459, 342, 319, 232]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[424, 301, 269, 214],\n",
       "        [419, 300, 269, 214],\n",
       "        [410, 280, 248, 205],\n",
       "        ...,\n",
       "        [424, 302, 275, 239],\n",
       "        [424, 302, 278, 240],\n",
       "        [421, 299, 274, 237]],\n",
       "\n",
       "       [[423, 300, 267, 213],\n",
       "        [421, 301, 270, 215],\n",
       "        [411, 282, 252, 209],\n",
       "        ...,\n",
       "        [427, 304, 279, 239],\n",
       "        [426, 304, 279, 241],\n",
       "        [422, 300, 274, 238]],\n",
       "\n",
       "       [[420, 295, 261, 207],\n",
       "        [420, 301, 265, 215],\n",
       "        [412, 283, 252, 212],\n",
       "        ...,\n",
       "        [426, 304, 282, 242],\n",
       "        [426, 304, 281, 242],\n",
       "        [423, 302, 275, 236]]], dtype=uint16)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_MSI_4chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img_MSI_4chan.shape[2] == 4:\n",
    "    img_MSI_4chan= (img_MSI_4chan- MSI_4chan_mean) / MSI_4chan_std\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.10253044, -0.88607359,  0.67372899, -1.15542854],\n",
       "        [-1.04845026, -0.8278406 ,  0.65770015, -1.16753388],\n",
       "        [-1.0123968 , -0.8278406 ,  0.65770015, -1.14332321],\n",
       "        ...,\n",
       "        [ 0.44776819,  0.80268306,  1.31488244, -0.92542722],\n",
       "        [ 0.55592855,  0.91914903,  1.49119964, -0.7680579 ],\n",
       "        [ 0.46579491,  0.82209405,  1.47517081, -0.71963657]],\n",
       "\n",
       "       [[-1.04845026, -0.86666259,  0.70578666, -1.14332321],\n",
       "        [-1.04845026, -0.78901861,  0.70578666, -1.14332321],\n",
       "        [-1.03042353, -0.76960761,  0.68975783, -1.13121788],\n",
       "        ...,\n",
       "        [ 0.48382164,  0.78327206,  1.34694011, -0.90121656],\n",
       "        [ 0.53790183,  0.88032704,  1.47517081, -0.7680579 ],\n",
       "        [ 0.28552763,  0.62798409,  1.41105546, -0.7317419 ]],\n",
       "\n",
       "       [[-0.99437007, -0.78901861,  0.70578666, -1.14332321],\n",
       "        [-1.03042353, -0.73078562,  0.7218155 , -1.13121788],\n",
       "        [-0.99437007, -0.75019662,  0.73784433, -1.10700721],\n",
       "        ...,\n",
       "        [ 0.30355436,  0.51151812,  1.17062291, -0.98595389],\n",
       "        [ 0.32158109,  0.56975111,  1.2507671 , -0.92542722],\n",
       "        [ 0.08723362,  0.41446314,  1.28282477, -0.8406899 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.54370187, -0.3813877 ,  0.48138295, -1.05858588],\n",
       "        [-0.63383551, -0.40079869,  0.48138295, -1.05858588],\n",
       "        [-0.79607606, -0.78901861,  0.14477739, -1.16753388],\n",
       "        ...,\n",
       "        [-0.54370187, -0.3619767 ,  0.57755597, -0.75595257],\n",
       "        [-0.54370187, -0.3619767 ,  0.62564248, -0.74384723],\n",
       "        [-0.59778205, -0.42020969,  0.56152713, -0.78016323]],\n",
       "\n",
       "       [[-0.56172859, -0.40079869,  0.44932528, -1.07069122],\n",
       "        [-0.59778205, -0.3813877 ,  0.49741179, -1.04648055],\n",
       "        [-0.77804933, -0.75019662,  0.20889274, -1.11911255],\n",
       "        ...,\n",
       "        [-0.48962168, -0.32315471,  0.64167132, -0.75595257],\n",
       "        [-0.50764841, -0.32315471,  0.64167132, -0.7317419 ],\n",
       "        [-0.57975532, -0.40079869,  0.56152713, -0.7680579 ]],\n",
       "\n",
       "       [[-0.61580878, -0.49785367,  0.35315226, -1.14332321],\n",
       "        [-0.61580878, -0.3813877 ,  0.41726761, -1.04648055],\n",
       "        [-0.7600226 , -0.73078562,  0.20889274, -1.08279655],\n",
       "        ...,\n",
       "        [-0.50764841, -0.32315471,  0.68975783, -0.71963657],\n",
       "        [-0.50764841, -0.32315471,  0.67372899, -0.71963657],\n",
       "        [-0.56172859, -0.3619767 ,  0.57755597, -0.79226856]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_MSI_4chan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_MSI_4chan[img_MSI_4chan!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.10253044, -0.88607359,  0.67372899, -1.15542854],\n",
       "        [-1.04845026, -0.8278406 ,  0.65770015, -1.16753388],\n",
       "        [-1.0123968 , -0.8278406 ,  0.65770015, -1.14332321],\n",
       "        ...,\n",
       "        [ 0.44776819,  0.80268306,  1.31488244, -0.92542722],\n",
       "        [ 0.55592855,  0.91914903,  1.49119964, -0.7680579 ],\n",
       "        [ 0.46579491,  0.82209405,  1.47517081, -0.71963657]],\n",
       "\n",
       "       [[-1.04845026, -0.86666259,  0.70578666, -1.14332321],\n",
       "        [-1.04845026, -0.78901861,  0.70578666, -1.14332321],\n",
       "        [-1.03042353, -0.76960761,  0.68975783, -1.13121788],\n",
       "        ...,\n",
       "        [ 0.48382164,  0.78327206,  1.34694011, -0.90121656],\n",
       "        [ 0.53790183,  0.88032704,  1.47517081, -0.7680579 ],\n",
       "        [ 0.28552763,  0.62798409,  1.41105546, -0.7317419 ]],\n",
       "\n",
       "       [[-0.99437007, -0.78901861,  0.70578666, -1.14332321],\n",
       "        [-1.03042353, -0.73078562,  0.7218155 , -1.13121788],\n",
       "        [-0.99437007, -0.75019662,  0.73784433, -1.10700721],\n",
       "        ...,\n",
       "        [ 0.30355436,  0.51151812,  1.17062291, -0.98595389],\n",
       "        [ 0.32158109,  0.56975111,  1.2507671 , -0.92542722],\n",
       "        [ 0.08723362,  0.41446314,  1.28282477, -0.8406899 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.54370187, -0.3813877 ,  0.48138295, -1.05858588],\n",
       "        [-0.63383551, -0.40079869,  0.48138295, -1.05858588],\n",
       "        [-0.79607606, -0.78901861,  0.14477739, -1.16753388],\n",
       "        ...,\n",
       "        [-0.54370187, -0.3619767 ,  0.57755597, -0.75595257],\n",
       "        [-0.54370187, -0.3619767 ,  0.62564248, -0.74384723],\n",
       "        [-0.59778205, -0.42020969,  0.56152713, -0.78016323]],\n",
       "\n",
       "       [[-0.56172859, -0.40079869,  0.44932528, -1.07069122],\n",
       "        [-0.59778205, -0.3813877 ,  0.49741179, -1.04648055],\n",
       "        [-0.77804933, -0.75019662,  0.20889274, -1.11911255],\n",
       "        ...,\n",
       "        [-0.48962168, -0.32315471,  0.64167132, -0.75595257],\n",
       "        [-0.50764841, -0.32315471,  0.64167132, -0.7317419 ],\n",
       "        [-0.57975532, -0.40079869,  0.56152713, -0.7680579 ]],\n",
       "\n",
       "       [[-0.61580878, -0.49785367,  0.35315226, -1.14332321],\n",
       "        [-0.61580878, -0.3813877 ,  0.41726761, -1.04648055],\n",
       "        [-0.7600226 , -0.73078562,  0.20889274, -1.08279655],\n",
       "        ...,\n",
       "        [-0.50764841, -0.32315471,  0.68975783, -0.71963657],\n",
       "        [-0.50764841, -0.32315471,  0.67372899, -0.71963657],\n",
       "        [-0.56172859, -0.3619767 ,  0.57755597, -0.79226856]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_MSI_4chan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_MSI_4chan = np.nan_to_num(img_MSI_4chan, nan=0)\n",
    "img_MSI_10chan = np.nan_to_num(img_MSI_10chan, nan=0)\n",
    "\n",
    "\n",
    "if True:\n",
    "    img_MSI_4chan = img_MSI_4chan.astype(np.float32)\n",
    "    img_MSI_10chan = img_MSI_10chan.astype(np.float32)\n",
    "\n",
    "if True:\n",
    "    RGB_3chan_mean = [123.675, 116.28, 103.53]\n",
    "    RGB_3chan_std = [58.395, 57.12, 57.375]\n",
    "    MSI_4chan_mean =[454.1608733420, 320.6480230485 , 238.9676917808 , 301.4478970428]\n",
    "    MSI_4chan_std =[55.4731833972, 51.5171917858, 62.3875607521, 82.6082214602]\n",
    "\n",
    "    if img_MSI_4chan.shape[2] == 4:\n",
    "        img_MSI_4chan_valid = img_MSI_4chan!=0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_MSI_4chan_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean = torch.tensor(MSI_4chan_mean).view(-1, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSI_4chan_mean = torch.tensor(MSI_4chan_mean).view(-1, 1, 1)\n",
    "MSI_4chan_std = torch.tensor(MSI_4chan_std).view(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (512,512,4) into shape (1048576,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimg_MSI_4chan\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg_MSI_4chan_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (img_MSI_4chan\u001b[38;5;241m-\u001b[39m MSI_4chan_mean) \u001b[38;5;241m/\u001b[39m MSI_4chan_std\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (512,512,4) into shape (1048576,)"
     ]
    }
   ],
   "source": [
    "img_MSI_4chan[img_MSI_4chan_valid] = (img_MSI_4chan- MSI_4chan_mean) / MSI_4chan_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (961720789.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if img_MSI_10chan.shape[2] == 10:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "        img_MSI_4chan[img_MSI_4chan_valid] = (img_MSI_4chan- MSI_4chan_mean) / MSI_4chan_std\n",
    "    \n",
    "    if img_MSI_10chan.shape[2] == 10:\n",
    "        img_MSI_10chan = img_MSI_10chan # S2 MSI 10通道的图像不需要归一化\n",
    "\n",
    "\n",
    "results['img_MSI_4chan'] = img_MSI_4chan\n",
    "results['img_MSI_10chan'] = img_MSI_10chan\n",
    "results['img_shape'] = img_MSI_4chan.shape[:2]\n",
    "results['ori_shape'] = img_MSI_4chan.shape[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atl-py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
